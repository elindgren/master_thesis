% Conclusions
    % - Accuracy/MSE för modeller - första delen av syftet
    % - Noder har analyserats, vissa funktionella nätverk kanske viktigare än andra men alla viktiga
    % - 21 noders data är för lite men har sina fördelar

% Future work
    % - Andra modeltyper
    % - Annat similarity measure
    % - Undersök mer högupplöst data
    % - Inkludera andra modaliteter av data (strukturell MRI etc.)
    % - Flera analysmetoder (Grad-CAM, öppna upp modellerna mer)
    % - Försök förstå varför just de här noderna är viktiga, inte bara att de är det. Vad händer egentligen i hjärnan?

\chapter{Conclusion and Outlook}

In this study, accurate models based on \acrshort{gcn}s for sex and brain age prediction using \acrshort{rs-fmri} data have been developed and analysed, with the goal of identifying functional brain networks that are related to sex and age. Three of the four studied models achieved comparable performance for both prediction tasks, with an accuracy of up to $79\,\%$ for sex classification a mean absolute error as low as $5.9\rm\,years$ for age prediction. From the saliency maps it was concluded that all functional brain networks are important for sex and brain age prediction, but that some are more important than others. Specifically, the most important network was the \acrlong{smm} (\acrshort{smm}) for both sex and age prediction, and additionally, the cerebellum was found to be important for age prediction. The main limitation of the work was found to be the low resolution of the \acrshort{rs-fmri} data used in this thesis.

There are several improvements that could be considered in future works. One possible improvement is to study the use of more high dimensional \acrshort{fmri} data. Another improvement is the inclusion of other data modalities, such as using both structural \acrshort{mri} and \acrshort{fmri} data. It is possible that such combined approaches could improve model performance. Different model types, not based on fully connected neural networks or \acrshort{gcn}s, could also be investigated. An example of such model types are various gradient-tree boosting algorithms, which have previously been applied to predicting brain age \cite{kaufmann}.

Studying different kinds of similarity measures is also a possible direction for future work. As previously mentioned, non-imaging data as in \cite{stankeviciute} can be used. This could increase model performance, but at the risk of introducing confounding variables that might make the analysis more difficult. If only imaging data is considered, as in this thesis, there are still several interesting approaches. One approach is to use graph-based similarity measures, such as in \cite{higcn}. Another approach is to train a machine learning model to predict the similarity between subjects. The model could thus be seen to compress the imaging data of two subjects into a single number. Finally, domain knowledge can also be used to design the similarity measure. For instance, a similarity measure based on comparing the functional connectivity could be improved by including information on the importance of nodes, e.g., by weighting each node's connections by its importance. 

Another direction for future work is to investigate other saliency mapping techniques, but also more general methods for explainability in AI. Both naive node removal and Zorro, used in this thesis, perform input-output analysis of the models. To further investigate the explainability of the models, one could consider using approaches that ``open-up'' the neural networks. In Yuan et al. \cite{yuan_survey} a review over possible analysis methods for \acrshort{gcn}s are presented. One example is Grad-CAM \cite{gradcam}, a method originally developed for analysing the gradients within \acrshort{cnn}s to draw conclusion on the importance of each pixel in the input image for predicting a certain class. Grad-CAM has been generalised to \acrshort{gcn}s, and was for instance used in both \cite{arslan} and \cite{understanding_gnn} to study the importance of functional brain networks for sex classification. We considered using Grad-CAM in this work, but were not able to due to time limitations. 

This thesis has mainly focused on gaining insight into which functional brain networks are important for predicting sex and brain age, without approaching the question of why they are important. To approach this question, more sophisticated methods for explainability could be used in order to gain a deeper neuroscientific understanding of the results. Explainability can be seen as the bridge that gaps the intersection between machine learning and neuroscience, and could possibly enable many interesting investigations in the years to come.

