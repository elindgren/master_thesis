\chapter{Results}


To reliably evaluate the models, the data set was split into a training/validation set and a test set. These data sets where then undersampled to make them unbiased, which yielded training/validation sets of size 30000 and 20000, and test sets of size  4678 and 3148 for sex and age prediction respectively. For age prediction, an unbiased data set corresponds to a uniform distribution of ages. All models where trained using the Adam optimizer. Furthermore, model training and evaluation was implemented using Keras with the Tensorflow backend. See Appendix \ref{app:model_training} for more details on the exact model architectures used. \todo{Bara modellerna beskrivs i appendix, ta bort!}

This chapter consists of two main parts. First, the results from training models for predicting sex and brain age from brain graphs will be presented. The models were first evaluated using ten folded cross validation on the training/validation set. Then, a final model was trained and evaluated on the test set. In the second part of the chapter, the analysis of these final models will be presented, with the aim of gaining insight into what functional brain networks are related to age and sex differences. 


\section{Model comparison}
\label{sec:model_pred}
The model performance for both sex and age prediction is presented in the form of the loss and two additional metrics. For sex classification these metrics are binary cross entropy (BCE) loss, accuracy and Matthews correlation coefficient (MCC). For age regression they are mean squared error (MSE), mean absolute error (MAE) and Pearssons correlation ($r$). MCC is identical to Pearsons correlation but refers to the performance of a binary classifier. A MCC of +1 thus indicates a perfect prediction, -1 all miss-predicted and 0 randomly guessing.

\subsection{Sex classification based on fMRI brain graphs}

To evaluate the model performance for sex classification, the three metrics calculated from cross-validation on the training/validation set are presented in \ref{tab:sex_model_results}.
\begin{table}[H]
    \centering
    \caption{Binary crossentropy loss (BCE), accuracy and Matthew's correlation coefficient (MCC) for each of the four models evaluated using ten-fold cross validation, with the mean and standard deviation calculated over the ten folds.}    
    \begin{tabular}{c|c|c|c}
         & BCE & Accuracy & MCC\\ \hline
        Baseline & $0.450\pm0.008$ & $0.790\pm0.006$ &$0.58\pm 0.01$\\
        GCN &$0.45\pm0.02$ & $0.792\pm0.009$& $0.59\pm0.02$\\
        Poptoy &$0.674\pm 0.006$ & $0.58\pm0.01$ &$0.17\pm0.02$\\
        Popencoder &$0.446\pm0.009$& $0.793\pm 0.006$ & $0.59\pm0.01$\\
    \end{tabular}
    \label{tab:sex_model_results}
\end{table}
All three metrics indicates that the Baseline, GCN and Popencoder models have comparable performance with an accuracy of about 79 \%. It is also clear that these three models significantly outperforms the Poptoy model whatever metric used. The performance of the final models, evaluated on an external test set, is presented in \ref{tab:sex_final_model_results}.
\begin{table}[H]
    \centering
    \caption{Binary crossentropy loss (BCE), accuracy and Matthew's correlation coefficient (MCC) for each of the four models evaluated on the test set.}
    \begin{tabular}{c|c|c|c}
         & BCE & Accuracy & MCC\\ \hline
        Baseline & 0.444 & 0.795 &0.59\\
        GCN & 0.43& 0.802 & 0.60 \\
        Poptoy &0.678 &0.574 &0.16\\
        Popencoder & 0.450 & 0.791& 0.59\\
    \end{tabular}
    \label{tab:sex_final_model_results}
\end{table}
The final models' performances are in line with the cross-validation results in table \ref{tab:sex_model_results}, where all metrics are within or around one standard deviation. Thus, the performance of the models generalises to external data.

The results presented in \ref{tab:sex_model_results} and \ref{tab:sex_final_model_results} have several interesting implications. First, there is basically no performance difference between Baseline, GCN and Popencoder, implying that increasing model complexity beyond Baseline is not necessary for classifying sex. 

Furthermore, the main difference between Popencoder and Baseline and GCN is that Popencoder takes a population graph as input in addition to the brain graphs for all subjects. One explanation of why including the population graph does not improve performance could be that the similarity measure does not introduce any extra information relevant for sex classification. Since the similarity measure is calculated from each subject's brain graph, it is possible that the information encoded by the similarity measure is only a subset of all the information contained in the individual graphs. Another explanation is that the similarity measure adds some extra information, but that the amount of information is small. In the case of either explanation, the similarity measure can be interpreted to not be very effective in improving the prediction of a subject's sex. 

That the similarity measure is not very effective is further supported by the poor performance of Poptoy relative to Popencoder. Both models are architecturally similar, with the difference that Poptoy only bases its prediction solely on the population graph. Hence, the results indicates that the information of similarity between subjects encoded in the popoulation graph is not enough for an accurate prediction for a subject's sex. However, the Poptoy model still performs slightly better than random guessing, indicating that some valuable information resides in the population graph. 

% Annan approach
% The results presented in \ref{tab:sex_model_results} and \ref{tab:sex_final_model_results} have several interesting implications. First, there is basically no performance difference between Baseline and GCN, implying that the increased complexity of GCN is not necessary. 

% Another interesting result is that Popencoder significantly outperforms the Poptoy model. Since the two models are architecturaly very similar, with the difference that Popencoder additionally takes subject brain graphs as input and compresses them using the Encoder, this indicates that Poptoy is missing vital information about individual subjects which for Popencoder is provided by the Encoder. A possible interpretation is that the information about similarities in the data set contained in the population graph is by itself not enough to make an accurate prediction for a subject's sex. However, the Poptoy model still performs slightly better than random guessing, indicating that some valuable information resides in the population graph. 

% Finally, it is also interesting to compare the subject-wise models, Baseline and GCN with the population graph models, Poptoy and Popencoder. The results are very similar for Baseline, GCN and Popencoder, once again indicating that increasing model complexity is unnecessary. In the case of Popencoder, the added model complexity comes from introducing the population graph. One explanation of why the population graph does not improve performance could be that the similarity measure does not introduce any extra information. Since the similarity measure is calculated from each subject's brain graph, it is possible that the information encoded by the similarity measure is only a subset of all the information contained in the individual graphs. Another explanation is that the similarity measure adds some extra information on the similarity between subjects, but that the amount of information is small. Too small to make a difference for the performance of Popencoder relative to Baseline and GCN, but large enough for Poptoy to perform better than random guessing. In the case of either explanation, the similarity measure can be interpreted to not be very informative in predicting a subject's sex. 

\subsection{Age}
To evaluate the model performance for age regression, the three metrics calculated from cross-validation is presented in \ref{tab:age_model_results}.

\begin{table}[H]
    \centering
    \caption{Mean squared error (MSE), mean absolute error (MAE) and Pearsson's correlation coefficient ($r$) for each of the four models evaluated using ten-fold cross validation, with the mean and standard deviation calculated over the ten folds.}
    \begin{tabular}{c|c|c|c}
         &  MSE & MAE & $r$ \\ \hline 
        Baseline &$52\pm1$& $5.9\pm0.1$&$0.52\pm0.01$\\
        GCN & $53\pm1$& $5.96\pm 0.09 $& $0.52\pm0.01$\\
        Poptoy &$71\pm 1$ & $7.24\pm0.07$ &$ 0.11\pm 0.01$\\
        Popencoder &$53\pm1$& $5.93\pm 0.09$ & $0.52\pm0.02$\\
    \end{tabular}
    \label{tab:age_model_results}
\end{table}
From table \ref{tab:age_model_results}, the three metrics clearly indicates that, just as for sex classification, Baseline, GCN and Popencoder all performs within the uncertainty of each other, while Poptoy performs significantly worse. The performance of the final models trained on all data and evaluated on an external test set, is presented in table \ref{tab:sex_final_model_results}. The results are within one standard deviation of the results in table \ref{tab:age_model_results}, which indicates that the models generalise well to external data. One possible exception is Popencoder, which performs slightly better on the test set than during cross-validation. However, the difference in performance is still small and could possibly be attributed to a fluke.

\begin{table}[H]
    \centering
    \caption{Mean squared error (MSE), mean absolute error (MAE) and Pearsson's correlation coefficient ($r$) for each of the four models evaluated on the test set.}
    \begin{tabular}{c|c|c|c}
         &  MSE & MAE & $r$ \\ \hline 
        Baseline & $51 $& $5.9 $&$0.53 $\\
        GCN & $51 $& $5.9  $& $0.53 $\\
        Poptoy &$71 $ & $7.18 $ &$ 0.09 $\\
        Popencoder &50 & $5.7 $ & $0.55 $\\
    \end{tabular}
    \label{tab:age_final_model_results}
\end{table}

The age prediction results for the different models are in line with the two main conclusions for sex classification in the previous section. First, Baseline, GCN and Popencoder perform very similarly which indicates that increasing the model complexity beyond Baseline is unnecessary. Secondly, the poor performance of Poptoy compared with the other models, combined with Popencoder not performing better than Baseline and GCN indicates that the similarity measure is not very informative with regards to age as well. 

To set the poor performance of Poptoy into perspective, consider a naive age prediction model that always outputs the average age of the population when predicting a subject's age. The performance of such a model on the test set would yield a MSE of $71$ and a MAE of $7.3$. The correlation for constant prediction with the actual ages is undefined. Comparing this with the results for Poptoy, one can conclude that Poptoy performs only slightly better, demonstrating Poptoy's poor performance.

Turning to the results on the test set for the three other models, all have a MSE loss of around 50--51 years$^2$, a MAE of 5.7--5.9 years and a correlation of around 0.53--0.55. An average error of around 5.7--5.9 years does not seem too bad, but focusing solely on the MAE or MSE can be misleading. The fact that the correlation is much lower than 1 indicates that the prediction is not perfect. In fact, it turns out that all these models are somewhat biased in predicting the mean of the age distribution in the data set. This can clearly be seen in figure \ref{} where a prediction with the baseline model for some fold on the test set is performed. The figure suggests that the model to some extent can determine if a subject is old or young, but that the error in the age prediction is much larger for younger and older subjects than for subjects close to the mean age. This is a form of underfitting, indicating either that the model is not complex or general enough to fit the data, or that the data does not contain enough information for predicting age.

\section{Analysis}
The analysis consisted of two methods: naive node masking and Zorro, which where both applied for sex and age prediction on the Baseline and GCN models. Poptoy was not analysed because of its low performance, and Popencoder because of its high complexity.

Naive node masking was performed with the loss evaluated on the test set. Thus, the change in binary cross-entropy ($\Delta$BCE) and mean squared error ($\Delta$MSE), compared to a reference model, indicates node importance for the sex and age prediction models respectively. The naive analysis was repeated ten times with different model initialisations to estimate the impact of model uncertainty on node importance. Zorro was performed with $\tau=0.9$ for the final models presented in section \ref{sec:model_pred}, due to it's computational complexity, but repeated for 25 different sub-groups of the test set. The variation in the Zorro results for these sub-groups represents the uncertainty in the importance for each node when varying subjects.


\subsection{Sex prediction}
\label{sec:results_analysis_sex}
As a measure of node importance, $\Delta$BCE when performing naive node masking for Baseline and GCN is presented in figures \ref{fig:naive_sex_baseline} and \ref{fig:naive_sex_gcn} respectively.

\begin{figure}[H]
    \centering
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/node_masking/sex_ffnn.pgf}
                }
            \end{center}
            \caption{Baseline}
            \label{fig:naive_sex_baseline}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/node_masking/sex_base.pgf}
                }
            \end{center}
            \caption{GCN}
            \label{fig:naive_sex_gcn}
        \end{subfigure}
    \caption{Results from performing the naive node removal analysis for Baseline and GCN, for sex prediction. The analysis was repeated for ten different model initializations, over which the dots and error bars in the figures represent the mean and standard deviation, respectively.}
    \label{fig:naive_sex}
\end{figure}

From the figures it is observed that the effect of removing a node for both models is on the order of $\Delta \text{BCE} \sim 0.01$, which is small compared to the absolute performance of the reference models $\text{BCE} \approx 0.45$. It is also observed that all nodes have a negative effect on the performance, $\Delta\text{BCE}>0$. These two observation indicates two things. First, no node seems to be crucial for the prediction, since the change in performance is small for all nodes. Secondly, all nodes are to some extent important, since removing any node has a negative impact on the performance. Despite the small absolute change in performance, there are clear differences in the relative importance between nodes. The results for both models indicates that node 12, 15, 16 and 20 are more important than the others. Further observe that the uncertainties are much larger for the GCN model then for the Baseline. This could be due to GCN not converging to the same degree as Baseline, either due to overfitting, early stopping or because of it being a more complex model. The two models gives however roughly the same result even if the uncertainties for GCN is large. 

The result from the Zorro analysis for Baseline and GCN is presented in figures \ref{fig:zorro_sex_baseline} and \ref{fig:zorro_sex_gcn}. The uncertainties in the result for both models are small, but note that they do not include potential uncertainties regarding the model variability. Model variability had great impact for the naive approach, but is believed to have much smaller effect for Zorro. This is motivated by the fact that the naive approach has very small differences in loss which makes small variations in the models have large effect. Small changes in the model will not affect the result from Zorro since two slightly different models will probably give the same explanations for a subject. For a more in depth investigation of these uncertainties see appendix ???. 

From figure \ref{fig:zorro_age_baseline} and \ref{fig:zorro_sex_gcn} it is clear that the results for Baseline and GCN are to a large extent in agreement: for both models node 12 is pointed out to be the most important node. Other nodes that may be regarded to somewhat important according to both models are nodes 15, 16, 17 and 20. It is also very interesting to note that node 8 seems to be more important when analysing the Baseline model than GCN. One possible interpretation could be that this is an artefact of the method, but this issue will be discussed more in-depth in chapter \ref{chap:discussion}. 

\begin{figure}[H]
    \centering
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/zorro/ffnn_sex_tau0.9.pgf}
                }
            \end{center}
            \caption{Baseline}
            \label{fig:zorro_sex_baseline}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/zorro/base_sex_tau0.9.pgf}
                }
            \end{center}
            \caption{GCN}
            \label{fig:zorro_sex_gcn}
        \end{subfigure}
    \caption{Zorro analysis results for the Baseline and GCN models. The analysis was run over 25 different groups of subjects for each model, to yield a mean and standard deviation in importance for each node.}
    \label{fig:zorro_sex}
\end{figure}

To more easily compare the result of the naive node masking and Zorro for both models figure \ref{fig:comparison_sex} is presented, without error bars for visibility reasons. The comparison of the result reveal that the methods are generally in agreement, but some clear differences exist. For instance, both methods agrees that node 12 is important but disagrees on the importance of node 15 and 16. Since both methods and both models are in agreement, node 12 seems to be most important node for classifying sex, and node 15, 16, 17 and 20 are to extent extent important.

\begin{figure}[H]
    \centering
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/node_masking/sex_ffnn_base.pgf}
                }
            \end{center}
            \caption{Naive}
            \label{fig:comparison_sex_naive}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/zorro/ffnn_base_sex_tau0.9.pgf}
                }
            \end{center}
            \caption{Zorro}
            \label{fig:comparison_sex_zorro}
        \end{subfigure}
    \caption{Comparison of the results for naive node masking and Zorro for sex prediction, in figures \ref{fig:naive_sex} and \ref{fig:zorro_sex} respectively. Note that the error bars are omitted for visibility.}
    \label{fig:comparison_sex}
\end{figure}



\subsection{Age prediction}
As a measure of node importance, $\Delta$MSE when performing naive node masking for Baseline and GCN is presented in figures \ref{fig:naive_age_baseline} and \ref{fig:naive_age_gcn} respectively. The general change in loss is observed in the figures to be small, $\Delta\text{MSE}\sim1$ relative to $\text{MSE}\sim50\text{ y}^2$. Similarly as for sex prediction, this indicates that no node is crucial and that all nodes are to some extent important for predicting age. Furthermore, the model uncertainty is larger for Baseline than for GCN in the case of age prediction as well, probably for the same reason as discussed in sex classification. Observe that the most important nodes for both models are nodes 12, 15 and 20, where node 1 is additionally important for Baseline. Overall, the models are generally in agreement with some small exceptions. 
\begin{figure}[H]
    \centering
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/node_masking/age_ffnn.pgf}
                }
            \end{center}
            \caption{Baseline}
            \label{fig:naive_age_baseline}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/node_masking/age_base.pgf}
                }
            \end{center}
            \caption{GCN}
            \label{fig:naive_age_gcn}
        \end{subfigure}
    \caption{Results from performing the naive node removal analysis for Baseline and GCN, for age prediction. The analysis was repeated for ten different model initializations, over which the dots and error bars in the figures represent the mean and standard deviation, respectively.}
    \label{fig:naive_age}
\end{figure}
The result from the Zorro analysis for Baseline and GCN is presented in figures \ref{fig:zorro_age_baseline} and \ref{fig:zorro_age_gcn}. From the figure it is observed that the algorithm finds node 1, 9, 12, 14, 15, and 16 important for Baseline and node 12 and 15 for GCN. These differences in what nodes are deemed important for the two models are significant due to the small uncertainties for Zorro, as discussed in section \ref{sec:results_analysis_sex}. Another observation is that generally the importance scores for Baseline are higher than for GCN, especially for nodes 1, 9 and 14. This means that more nodes are required in the explanations for Baseline than for GCN in order to reach a fidelity of $\tau>0.9$.

\begin{figure}[H]
    \centering
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/zorro/ffnn_age_tau0.9.pgf}
                }
            \end{center}
            \caption{Baseline}
            \label{fig:zorro_age_baseline}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/zorro/base_age_tau0.9.pgf}
                }
            \end{center}
            \caption{GCN}
            \label{fig:zorro_age_gcn}
        \end{subfigure}
    \caption{Zorro analysis results for the Baseline and GCN models for age prediction. The analysis was run over 25 different groups of subjects for each model, to yield a mean and standard deviation in importance for each node.}
    \label{fig:zorro_age}
\end{figure}


In order to more easily compare the result for the naive node masking and Zorro for both models, figure \ref{fig:comparison_age} is presented. By comparing the results for both methods and models node 12 and 15 stand out since they are deemed important in all cases. In addition to node 12 and 15, other nodes that might be important but not consistently for all methods and models are 1, 9, 14, 16 and 20. Most of these are nodes that are only considered important by Zorro for the Baseline model. However, since they are only deemed important in one out of the four cases, it might suggest that they are artefacts of the method or model.
There are also some differences in the results for naive node masking compared with Zorro. For example, node 20 may be deemed more important by the naive method. However, the differences between the two analysis methods seems to be smaller than the discrepancy between Baseline and GCN for Zorro. Both the discrepancy between Baseline and GCN for Zorro, and the differences between the two analysis methods will be discussed in more detail in chapter \ref{chap:discussion}.

\begin{figure}[H]
    \centering
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/node_masking/age_ffnn_base.pgf}
                }
            \end{center}
            \caption{Naive}
            \label{fig:comparison_age_naive}
        \end{subfigure}%
        \begin{subfigure}{.5\textwidth}
            \centering
            \begin{center}
                \resizebox {1.0\linewidth} {!} {
                    \input{chapters/images_results/zorro/ffnn_base_age_tau0.9.pgf}
                }
            \end{center}
            \caption{Zorro}
            \label{fig:comparison_age_zorro}
        \end{subfigure}
    \caption{Comparison of the results for naive node masking and Zorro for age prediction, in figures \ref{fig:naive_sex} and \ref{fig:zorro_sex} respectively. Note that the error bars are omitted for visibility.}
    \label{fig:comparison_age}
\end{figure}